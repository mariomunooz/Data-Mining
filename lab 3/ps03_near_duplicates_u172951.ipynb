{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J78pEDkLHnnJ"
      },
      "source": [
        "# Practice Session 03: Find near-duplicates using shingling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YUaiRebHnnL"
      },
      "source": [
        "In this session we will take a large corpus of tweets and detect near-duplicates on this corpus using a technique known as *shingling*.\n",
        "\n",
        "Two documents are considered near-duplicates if they share a large amount of ngrams. The *ngrams* of a phrase are overlapping sequences of words of length *n*. For instance, the phrase '*Never let them guess your next move.*' has the following 3-grams:\n",
        "\n",
        "* 'never let them'\n",
        "* 'let them guess'\n",
        "* 'them guess your'\n",
        "* 'guess your next'\n",
        "* 'your next move'\n",
        "\n",
        "To measure the similarity between two sets, we will use the [Jaccard index](https://en.wikipedia.org/wiki/Jaccard_index), which is the size of the intersection of the two sets divided by their union. This values goes between 0.0 (meaning the documents have no ngrams in common) to 1.0 (meaning the documents have the same ngrams).\n",
        "\n",
        "To speed up things, instead of comparing the set of shingles of two documents which can be large, we will derive a fixed-length *signature* or *sketch* for each document. This will be obtained by (1) applying a random permutation to the list of possible ngrams, and (2) pick the ngram that appears first in the permuted list. The Jaccard index between these signatures will be a good approximation of the Jaccard index between the original sets of ngrams. \n",
        "\n",
        "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnTfRJvAHnnM"
      },
      "source": [
        "Author: <font color=\"blue\">Mario Mu√±oz Serrano</font>\n",
        "\n",
        "E-mail: <font color=\"blue\">mario.munoz01@estudiant.upf.edu</font>\n",
        "\n",
        "Date: <font color=\"blue\">03/10/2022</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeIjUyaMHnnN"
      },
      "source": [
        "# 0. Dataset\n",
        "\n",
        "The corpus you will use contains about 35,500 messages (\"tweets\") posted between March 13th, 2020, and March 14th, 2020, containing a hashtag or keyword related to COVID-19, and posted by a user declaring a location in Catalonia.\n",
        "\n",
        "The tweets are in a format known as [JSON](https://en.wikipedia.org/wiki/JSON#Example). Python's JSON library takes care of translating it into a dictionary.\n",
        "\n",
        "Then, the file is compressed using `gzip`, and can be compressed with the `gunzip` command, although we will read it in compressed form. The file is named `CovidLockdownCatalonia.json.gz`.\n",
        "\n",
        "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "czTD2-nWHnnO"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import json\n",
        "import gzip\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from timeit import default_timer as timer\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORT DATASETS FROM DRIVE\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlVCG3B8Iake",
        "outputId": "763037a6-5a87-483c-d6c9-0bf50f3cdd1c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/Data Mining/data\"\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc4KyA-VIqOj",
        "outputId": "84164fe0-cc39-4126-e219-d96e8912a27c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Data Mining/data\n",
            "CovidLockdownCatalonia.json.gz  device_db.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5atDY8DHnnO",
        "outputId": "fdf621a6-e168-4be8-871a-aa0da5b1616e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 10000 documents\n"
          ]
        }
      ],
      "source": [
        "# Input file\n",
        "INPUT_FILENAME = \"CovidLockdownCatalonia.json.gz\"\n",
        "\n",
        "# Array for storing messages\n",
        "messages = []\n",
        "MAX_MESSAGES = 10000\n",
        "\n",
        "with gzip.open(INPUT_FILENAME, \"rt\", encoding=\"utf-8\") as input_file:\n",
        "    \n",
        "    messages_read = 0\n",
        "    for line in input_file:\n",
        "            \n",
        "        # Read message\n",
        "        tweet = json.loads(line)\n",
        "\n",
        "        # Keep only messages in Catalan\n",
        "        if tweet[\"lang\"] == \"ca\":\n",
        "            \n",
        "            messages_read += 1\n",
        "            \n",
        "            if messages_read <= MAX_MESSAGES:\n",
        "                author = tweet[\"user\"][\"screen_name\"]\n",
        "                message = tweet[\"full_text\"]\n",
        "                messages.append(message)\n",
        "\n",
        "print(\"Read %d documents\" % len(messages))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4mEGsAWHnnP"
      },
      "source": [
        "# 1. Auxiliary functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_VqQ1ifHnnQ"
      },
      "source": [
        "Implement the Jaccard similarity between two lists: the size of the intersection of two sets, divided by the size of their union.\n",
        "\n",
        "You can use set operations: `set(l)` to convert a list `l` to a set, then `set1.union(set2)` and `set1.intersection(set2)` to compute union and intersection of sets `set1`, `set2`. Learn more in this [tutorial on set operations](https://learnpython.com/blog/python-set-operations/)\n",
        "\n",
        "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PkEOvN2HnnQ"
      },
      "source": [
        "<font size=\"+1\" color=\"red\">Replace this cell with your code for function \"jaccard_similarity\"</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard_similarity(array1, array2):\n",
        "\n",
        "  set1 = set(array1)\n",
        "  set2 = set(array2)\n",
        "\n",
        "  union = set2.union(set1)\n",
        "  intersection = set2.intersection(set1)\n",
        "\n",
        "  empty = (len(union) == 0) & (len(intersection) == 0)\n",
        "\n",
        "  if not empty:\n",
        "    jaccard_index = len(intersection)/len(union)\n",
        "\n",
        "    return jaccard_index\n",
        "  \n",
        "  return 0"
      ],
      "metadata": {
        "id": "8FrZDAmBdGqi"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFYo170dHnnR"
      },
      "source": [
        "Write code to test your function. Your tests cases should be:\n",
        "\n",
        "1. Two arrays for which the jaccard similarity is 0.6666...\n",
        "1. Two arrays for which the jaccard similarity is 0.75\n",
        "1. Two arrays for which the jaccard similarity is 1.0\n",
        "1. Two empty arrays should have jaccard similarity 0.0\n",
        "\n",
        "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSmBR24uHnnS"
      },
      "source": [
        "<font size=\"+1\" color=\"red\">Replace this cell with your code testing \"jaccard_similarity\"</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_jaccard():\n",
        "  a = [1, 2, 3, 4]\n",
        "  b = [1, 2, 3, 5]\n",
        "  c = [1, 2, 3]\n",
        "  d = []\n",
        "\n",
        "  pairs = [[a, a], [a, b], [b, c], [d,d]]\n",
        "\n",
        "  for pair in pairs:\n",
        "    print(f'For arrays a = {pair[0]} and b = {pair[1]} their jaccard similarity is: {jaccard_similarity(pair[0], pair[1])}')\n",
        "\n",
        "\n",
        "test_jaccard()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X49RZX1xf1-Q",
        "outputId": "a179b050-bc78-427f-9efe-0e9868938345"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For arrays a = [1, 2, 3, 4] and b = [1, 2, 3, 4] their jaccard similarity is: 1.0\n",
            "For arrays a = [1, 2, 3, 4] and b = [1, 2, 3, 5] their jaccard similarity is: 0.6\n",
            "For arrays a = [1, 2, 3, 5] and b = [1, 2, 3] their jaccard similarity is: 0.75\n",
            "For arrays a = [] and b = [] their jaccard similarity is: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c89wpfoeHnnT"
      },
      "source": [
        "Implement a function `clean` that cleans-up text according to this specification:\n",
        "\n",
        "1. Removing \"RT \" prefixes\n",
        "1. Converting to lowercase\n",
        "1. [Romanizing](https://en.wikipedia.org/wiki/Romanization) text, replacing \"√ë\" by \"n\", \"√±\" by \"n\", \"√≥\" by \"o\", \"√†\" by \"a\", \"l¬∑l\" by \"ll\", and so on.\n",
        "1. Removing URLs, both \"http\" and \"https\" ones.\n",
        "1. Removing spaces at the beginning and spaces at the end with the `strip()` function.\n",
        "1. Removing anything that remains that is not a letter or digit\n",
        "1. Changing double spaces to single spaces.\n",
        "\n",
        "You can use `text.lower()` to convert to lowercase, and then `re.sub(...)` to replace parts of the text. See [Python regexps](https://docs.python.org/3/library/re.html).\n",
        "\n",
        "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm0x9_E9HnnU"
      },
      "source": [
        "<font size=\"+1\" color=\"red\">Replace this cell with your code for function \"clean\"</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean(string):\n",
        "\n",
        "  if 'RT @' in string: \n",
        "    string = string.split('RT @')\n",
        "    string = string[1]\n",
        "  \n",
        "  string = string.lower()\n",
        "\n",
        "  string = re.sub('(https?://[^\\s]+)', '', string)\n",
        "  string = re.sub('https', '', string)\n",
        "  string = re.sub('http', '', string)\n",
        "\n",
        "  romanizing_mapping = [ [u'[√°√†√¢√§√£√•]', 'a'], [u'[√©√®√™√´]', 'e'], [u'[√≠√¨√Æ√Ø]', 'i'], [u'[√≥√≤√¥√∂√µ]', 'o'], [u'[√∫√π√ª√º]', 'u'], [u'[√±]', 'n'], [u'[√ßƒçƒá]', 'c'], [u'[√Ω√ø]', 'y'] ]\n",
        "\n",
        "  for mapping in romanizing_mapping:\n",
        "    string = re.sub(mapping[0], mapping[1], string)\n",
        "\n",
        "  string = re.sub(r'[^a-zA-Z0-9 ]', '', string)\n",
        "\n",
        "  string = \" \".join(string.split())\n",
        "  \n",
        "  return string.strip()"
      ],
      "metadata": {
        "id": "pmJOX8Gtr82c"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdWm1DBkHnnU"
      },
      "source": [
        "Test your function by passing it five different texts including punctuation, non-Roman characters, URLs, etc. Make sure your test cases cover all the required aspects of the specification.\n",
        "\n",
        "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uknu_uYpHnnV"
      },
      "source": [
        "<font size=\"+1\" color=\"red\">Replace this cell with your code testing function \"clean\"</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = [messages[i] for i in range(10)]\n",
        "c = 1\n",
        "for i in sample:\n",
        "  print(f'TWEET {c}\\n-NOT CLEANED:\\n\\t{i}\\n-CLEANED:\\n\\t{clean(i)}\\n-------------------------')\n",
        "  c += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIr-4GMEkU8n",
        "outputId": "f9b9a8b6-b23a-4186-beb3-d158afacb22e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TWEET 1\n",
            "-NOT CLEANED:\n",
            "\tRT @aramateix: La gesti√≥ del tel√®fon d'atenci√≥ 061 dep√®n de Ferrovial. La decisi√≥ del @govern NO modifica aix√≤. La gent no pagar√† de manera‚Ä¶\n",
            "-CLEANED:\n",
            "\taramateix la gestio del telefon datencio 061 depen de ferrovial la decisio del govern no modifica aixo la gent no pagara de manera\n",
            "-------------------------\n",
            "TWEET 2\n",
            "-NOT CLEANED:\n",
            "\tRT @Totbadalona: ü¶†Els restaurants han de reduir el seu aforament en un 66% per garantir la seguretat davant del coronavirus #Badalona https‚Ä¶\n",
            "-CLEANED:\n",
            "\ttotbadalona els restaurants han de reduir el seu aforament en un 66 per garantir la seguretat davant del coronavirus badalona\n",
            "-------------------------\n",
            "TWEET 3\n",
            "-NOT CLEANED:\n",
            "\tRT @XSalaimartin: Fa temps que sabem que aquest tal Garcia-Page √©s un miserable. Per√≤ amb aix√≤ se supera fins i tot a s√≠ mateix. https://t.‚Ä¶\n",
            "-CLEANED:\n",
            "\txsalaimartin fa temps que sabem que aquest tal garciapage es un miserable pero amb aixo se supera fins i tot a si mateix\n",
            "-------------------------\n",
            "TWEET 4\n",
            "-NOT CLEANED:\n",
            "\tRT @marctarinmarti: 2. La transmissi√≥ de la #COVID19 √©s per gotes. Per tant, ra√≥ de m√©s de recloure's a casa si presenteu tos, febre, mucos‚Ä¶\n",
            "-CLEANED:\n",
            "\tmarctarinmarti 2 la transmissio de la covid19 es per gotes per tant rao de mes de recloures a casa si presenteu tos febre mucos\n",
            "-------------------------\n",
            "TWEET 5\n",
            "-NOT CLEANED:\n",
            "\tRT @MACanadell: Heu vist algun ministre dan√®s, corea, it√†lia o xin√®s plorant en roda de premsa pel #COVID19 ?\n",
            "\n",
            "No. Perqu√® els ministres no‚Ä¶\n",
            "-CLEANED:\n",
            "\tmacanadell heu vist algun ministre danes corea italia o xines plorant en roda de premsa pel covid19 no perque els ministres no\n",
            "-------------------------\n",
            "TWEET 6\n",
            "-NOT CLEANED:\n",
            "\tRT @angeliufus: Test #COVID19 a TOTA la poblaci√≥ ja i A√èLLAMENT, som a dies de 2248 casos i q morin 150 pers AL DIA com AHIR a It√†lia. ‚ÄúAcc‚Ä¶\n",
            "-CLEANED:\n",
            "\tangeliufus test covid19 a tota la poblacio ja i aillament som a dies de 2248 casos i q morin 150 pers al dia com ahir a italia acc\n",
            "-------------------------\n",
            "TWEET 7\n",
            "-NOT CLEANED:\n",
            "\tRT @FincaSantaMarga: Sou uns irresponsables i uns fan√†tics. En uns moments aix√≠... i nom√©s pensant en collonades. Perqu√® aquest tall ara ma‚Ä¶\n",
            "-CLEANED:\n",
            "\tfincasantamarga sou uns irresponsables i uns fanatics en uns moments aixi i nomes pensant en collonades perque aquest tall ara ma\n",
            "-------------------------\n",
            "TWEET 8\n",
            "-NOT CLEANED:\n",
            "\tRT @VilaWeb: [EN DIRECTE] Comen√ßa el confinament d‚ÄôIgualada i tres municipis m√©s pel brot de la Covid-19  https://t.co/AaRxRc0Wwp\n",
            "-CLEANED:\n",
            "\tvilaweb en directe comenca el confinament digualada i tres municipis mes pel brot de la covid19\n",
            "-------------------------\n",
            "TWEET 9\n",
            "-NOT CLEANED:\n",
            "\tRT @VilaWeb: Coronavirus: √©s l‚Äôhora de treure la part millor de nosaltres I Editorial de @vpartal https://t.co/BitMIGtRJY\n",
            "-CLEANED:\n",
            "\tvilaweb coronavirus es lhora de treure la part millor de nosaltres i editorial de vpartal\n",
            "-------------------------\n",
            "TWEET 10\n",
            "-NOT CLEANED:\n",
            "\tRT @elsquissos: Ens en sortirem! #COVID19. Per√≤ tenim un dubte! ü§î\n",
            "En cas de confinament, podr√≠eu informar-nos dels permisos o del qu√® cal f‚Ä¶\n",
            "-CLEANED:\n",
            "\telsquissos ens en sortirem covid19 pero tenim un dubte en cas de confinament podrieu informarnos dels permisos o del que cal f\n",
            "-------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBdugHbgHnnV"
      },
      "source": [
        "# 2. Implement an n-gram extractor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *ngrams* of a phrase are overlapping sequences of words of length *n*. For instance, the phrase '*Never let them guess your next move.*' has the following 3-grams:\n",
        "\n",
        "* 'never let them'\n",
        "* 'let them guess'\n",
        "* 'them guess your'\n",
        "* 'guess your next'\n",
        "* 'your next move'\n"
      ],
      "metadata": {
        "id": "THFH3oVZHRVp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGKihsOeHnnV"
      },
      "source": [
        "Implement the function `ngrams(text,size)`, which should produce all sub-sequences of `size` words present in the text. Use the following skeleton:\n",
        "\n",
        "```python\n",
        "MIN_TOKEN_LENGTH = 2\n",
        "\n",
        "def ngrams(text, size):\n",
        "    tokens = clean(text).split()\n",
        "    ngrams = []\n",
        "    # your code here\n",
        "    return ngrams\n",
        "```\n",
        "\n",
        "Note that `ngrams` is a list, and each element of a list is a *string*.\n",
        "\n",
        "The only words you must consider in a ngram are words having at least `MIN_TOKEN_LENGTH` characters.\n",
        "\n",
        "You can use the [split](https://docs.python.org/2/library/string.html#string.split) and [join](https://docs.python.org/2/library/string.html#string.join) function of the split library. Remember that to extract elements *i* to *j* of array *a* you use `a[i:j]`.\n",
        "\n",
        "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZOJgI6aHnnW"
      },
      "source": [
        "<font size=\"+1\" color=\"red\">Replace this cell with your code implementing function \"ngrams(text,size)\"</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MIN_TOKEN_LENGTH = 2\n",
        "\n",
        "def ngrams(text, size):\n",
        "    tokens = clean(text).split()\n",
        "\n",
        "    # your code here\n",
        "    tokens = [token for token in tokens if len(token) >= MIN_TOKEN_LENGTH]\n",
        "    ngrams = [\" \".join(tokens[i:i+size]) for i in range(len(tokens)-(size-1))]\n",
        "      \n",
        "    return ngrams"
      ],
      "metadata": {
        "id": "OzYOhWZgEcOc"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYdE3_6_HnnW"
      },
      "source": [
        "Test your function:\n",
        "\n",
        "```python\n",
        "print(messages[9780])\n",
        "print(ngrams(messages[9780], 2))\n",
        "```\n",
        "\n",
        "Should print:\n",
        "\n",
        "```\n",
        "RT @diariARA: Comerciants xinesos donen mascaretes i gel antis√®ptic a Badalona per lluitar contra el coronavirus https://t.co/ybYXFxphIu\n",
        "['diariara comerciants', 'comerciants xinesos', 'xinesos donen', 'donen mascaretes', 'mascaretes gel', 'gel antiseptic', 'antiseptic badalona', 'badalona per', 'per lluitar', 'lluitar contra', 'contra el', 'el coronavirus']\n",
        "```\n",
        "\n",
        "Remember that `ngrams` should return a list of string, not a list of lists, so carefully check that you are returning a list of strings and not a list of lists.\n",
        "\n",
        "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVcg9d9iHnnW"
      },
      "source": [
        "<font size=\"+1\" color=\"red\">Replace this cell with your code testing function \"ngrams\"</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(messages[9780])\n",
        "print(ngrams(messages[9780], 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD5I5j34JkT7",
        "outputId": "2ee3a2d9-30d0-4b8c-a510-29e2aea7e756"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RT @diariARA: Comerciants xinesos donen mascaretes i gel antis√®ptic a Badalona per lluitar contra el coronavirus https://t.co/ybYXFxphIu\n",
            "['diariara comerciants', 'comerciants xinesos', 'xinesos donen', 'donen mascaretes', 'mascaretes gel', 'gel antiseptic', 'antiseptic badalona', 'badalona per', 'per lluitar', 'lluitar contra', 'contra el', 'el coronavirus']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqXneF6iHnnW"
      },
      "source": [
        "# 3. Estimation for brute force method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsphpXX9HnnX"
      },
      "source": [
        "The following code, which you should leave as-is, computes the time it takes to compare all first *limit* messages against all first *limit* messages in the array.\n",
        "\n",
        "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "wQnlS-XfHnnX"
      },
      "outputs": [],
      "source": [
        "# LEAVE AS-IS\n",
        "\n",
        "def time_brute_force_similarities(messages, limit, ngram_size):\n",
        "    if limit > len(messages):\n",
        "        raise ValueError(\"Limit should be less than or equal than the number of messages\")\n",
        "        \n",
        "    # Start a timer\n",
        "    start = timer()\n",
        "\n",
        "    # Iterate through document identifiers\n",
        "    for docid1 in range(np.min([len(messages), limit])):\n",
        "\n",
        "        # Clean document 1 and extract ngrams\n",
        "        doc1 = clean(messages[docid1])\n",
        "        ngrams1 = ngrams(doc1, ngram_size)\n",
        "\n",
        "        # Iterate through document identifiers larger than doc2\n",
        "        for docid2 in range(docid1+1, np.min([len(messages), limit])):\n",
        "                         \n",
        "            # Clean document 2 and extract ngrams\n",
        "            doc2 = clean(messages[docid2])\n",
        "            ngrams2 = ngrams(doc2, ngram_size)\n",
        "\n",
        "            # Compute similarity\n",
        "            similarity = jaccard_similarity(ngrams1, ngrams2)\n",
        "\n",
        "    end = timer()\n",
        "    return(end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7ETj413HnnX"
      },
      "source": [
        "Use the function above to create a plot in which you have in the x axis the number of messages to check, and in the y axis the time it takes to check that many messages if we use ngrams of size 3. Try with x from *1* to *2001* in increments of *150* (use the [range](https://docs.python.org/3/library/functions.html#func-range) function).\n",
        "\n",
        "In this plot, remember to include labels in both axes.\n",
        "\n",
        "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK5vwabeHnnY"
      },
      "source": [
        "<font size=\"+1\" color=\"red\">Replace this cell with your code for generating the requested plot. Remember to label the x and y axis.</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m_num = []\n",
        "time = []\n",
        "\n",
        "for i in range(1, 2001, 150):\n",
        "  m_num.append(i)\n",
        "  time.append(time_brute_force_similarities(messages, i, 3))\n",
        "    \n",
        "\n",
        "plt.plot(m_num, time)\n",
        "plt.title('Brute force similarities performance\\n')\n",
        "plt.xlabel('Number of messages to check')\n",
        "plt.ylabel('time spent (seconds)')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "kf1cmNq4TgmX",
        "outputId": "2eb86fb7-526d-4fb8-993c-4782c8e95c0d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTY7oUjnHnnY"
      },
      "source": [
        "<font size=\"+1\" color=\"red\">Replace this cell with (1) a brief commmentary about what you see in this plot, and (2) your estimate for how long it would take to run the brute force similarity computations for the entire input matrix. Express your estimation in hours, minutes, and seconds. Justify precisely your calculations.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p382-EHOHnnY"
      },
      "source": [
        "# 4. Computing the doc-ngram matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hcmQRRpHnnY"
      },
      "source": [
        "Now we will compute a matrix in which every row is an ngram, and every column is a document.\n",
        "\n",
        "In real-world implementations, this is done by hashing the ngrams and then every row is an ngram *hash*; in this practice we will skip that step and work directly with one ngram per row, which is conceptually the same and easier to code.\n",
        "\n",
        "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUyi5nX6HnnZ"
      },
      "source": [
        "## 4.1 Create list of all ngrams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDSaPvffHnnZ"
      },
      "source": [
        "Implement code to create:\n",
        "\n",
        "* the dictionary `ngram_to_index`, which should convert an ngram to an index (a row number),\n",
        "* the dictionary `index_to_ngram`, which should convert an index to an ngram, and\n",
        "* the variable `num_distinct_ngrams` which should contain the number of distinct ngrams.\n",
        "\n",
        "You can use the following template:\n",
        "\n",
        "```python\n",
        "NGRAM_SIZE = 3\n",
        "\n",
        "ngram_to_index = {}\n",
        "index_to_ngram = {}\n",
        "next_index = 0\n",
        "\n",
        "for message in messages:\n",
        "    all_ngrams = ngrams(message, NGRAM_SIZE)\n",
        "    for ngram in all_ngrams:\n",
        "        # YOUR CODE HERE\n",
        "            \n",
        "num_distinct_ngrams = next_index\n",
        "\n",
        "print(\"There are %d distinct ngrams in the %d documents\" % (num_distinct_ngrams, len(messages)))\n",
        "```\n",
        "\n",
        "Note that the total number of n-grams may vary depending on ho you `clean()` text. In this dataset it should be about 10 times the number of documents.\n",
        "\n",
        "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz7hyyOaHnnZ"
      },
      "source": [
        "<font size=\"+1\" color=\"red\">Replace this cell with your code for creating the ngram_to_index dictionary.</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NGRAM_SIZE = 3\n",
        "\n",
        "ngram_to_index = {}\n",
        "index_to_ngram = {}\n",
        "next_index = 0\n",
        "stored = set()\n",
        "\n",
        "\n",
        "for message in messages:\n",
        "    all_ngrams = ngrams(message, NGRAM_SIZE)\n",
        "\n",
        "    if len(clean(message).split()) > NGRAM_SIZE:\n",
        "        for ngram in all_ngrams:\n",
        "            \n",
        "            if not ngram in stored:\n",
        "              \n",
        "              stored.add(ngram)\n",
        "              ngram_to_index[ngram] = next_index\n",
        "              index_to_ngram[next_index] = ngram\n",
        "              next_index += 1\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "num_distinct_ngrams = next_index\n",
        "\n",
        "print(\"There are %d distinct ngrams in the %d documents\" % (num_distinct_ngrams, len(messages)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2yc1yEYf5uv",
        "outputId": "eb761c01-dc08-4da5-ae2f-5da896cc809b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 67013 distinct ngrams in the 10000 documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGX7CZSLHnnZ"
      },
      "source": [
        "Test your function by printing the `ngram_to_index` of the strings `\"tancat escoles fins\"` and `\"garantir la seguretat\"`. The exact index varies,  depending on how you `clean()` text. Then, print the `index_to_ngram` of the returned index, and should give you the same string.\n",
        "\n",
        "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfHDy2V1HnnZ"
      },
      "source": [
        "<font size=\"+1\" color=\"red\">Replace this cell with your code for testing the ngram_to_index structure.</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strings = ['tancat escoles fins', 'garantir la seguretat']\n",
        "\n",
        "for string in strings:\n",
        "  index = ngram_to_index[string]\n",
        "\n",
        "  print(f\"The index of {string} is: {ngram_to_index[string]}\")\n",
        "  print(f\"The ngram in index {index} is: {index_to_ngram[index]}\")\n",
        "  print('--')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_poUG8dNoxw",
        "outputId": "648632cd-29a5-4f97-e25e-31fffd027e2c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The index of tancat escoles fins is: 938\n",
            "The ngram in index 938 is: tancat escoles fins\n",
            "--\n",
            "The index of garantir la seguretat is: 34\n",
            "The ngram in index 34 is: garantir la seguretat\n",
            "--\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbc-s8NLHnna"
      },
      "source": [
        "## 4.2 Create table ngrams x documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y45ZI2t9Hnna"
      },
      "source": [
        "Now we will create a boolean matrix named `M_ngram_doc`, where each row should be an n-gram, and each column should be a document.\n",
        "\n",
        "There might be documents having less than *NGRAM_SIZE* words and thus containing no shingles. You can skip those documents above (when reading the file), or handle them here.\n",
        "\n",
        "The next code creates an empty matrix. Leave as-is. If you run out of memory, limit the number of documents you read at the beginning of this file, for instance, read only the first 10,000 or the first 7,000 documents, and then try again.\n",
        "\n",
        "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ysl9Lw5Hnna",
        "outputId": "82a0c5ab-5ce1-4cc8-ebb9-43efc5849903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix dimensions: 67013 rows (distinct shingles) x 10000 columns (distinct documents)\n"
          ]
        }
      ],
      "source": [
        "# LEAVE AS-IS\n",
        "\n",
        "# Create dense matrix in which every cell contains the value \"False\"\n",
        "M_ngram_doc = np.full((num_distinct_ngrams, len(messages)), False)\n",
        "\n",
        "# Print the number of rows and columns of this matrix\n",
        "# numpy.matrix.shape is a tuple, shape[0] is the number of rows, shape[1] the number of columns\n",
        "print(\"Matrix dimensions: %d rows (distinct shingles) x %d columns (distinct documents)\" % M_ngram_doc.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ_jA-B0Hnnb"
      },
      "source": [
        "Complete the matrix `M_ngram_doc` so that position i, j (row, column) holds a `True` if document j contains ngram i, otherwise holds `False`.\n",
        "\n",
        "You can use the following template:\n",
        "\n",
        "```python\n",
        "for docid in range(len(messages)):\n",
        "    message = messages[docid]\n",
        "    all_ngrams = ngrams(message, ngram_size)\n",
        "    for ngram in all_ngrams:\n",
        "        # replace this comment with your code\n",
        "```\n",
        "\n",
        "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLoVCuwOHnnb"
      },
      "source": [
        "<font size=\"+1\" color=\"red\">Replace this cell with your code for filling the M_ngram_doc matrix.</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for docid in range(len(messages)):\n",
        "    message = messages[docid]\n",
        "    all_ngrams = ngrams(message, NGRAM_SIZE)\n",
        "    if len(clean(message).split()) > NGRAM_SIZE:\n",
        "        for ngram in all_ngrams:\n",
        "            # replace this comment with your code\n",
        "            \n",
        "            index = ngram_to_index[ngram]\n",
        "            M_ngram_doc[index][docid] = True"
      ],
      "metadata": {
        "id": "y702gvuNPEwi"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doU178V5Hnnb"
      },
      "source": [
        "Measure the density of this matrix, as a percentage. This is the number of non-zeroes in the matrix as a percentage of the number of cells of the matrix.\n",
        "\n",
        "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04CDfRKAHnnc"
      },
      "source": [
        "<font size=\"+1\" color=\"red\">Replace this cell with your code for printing the density of the M_ngram_doc matrix as a percentage.</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'The density of the matrix is {round((M_ngram_doc.sum()/M_ngram_doc.size)*100, 3)}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ayGkcjUbIYr",
        "outputId": "3680aa9b-654b-4a15-9e53-d5318e594016"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The density of the matrix is 0.023%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQMUv2ZMHnnc"
      },
      "source": [
        "Print a couple of documents (columns). All columns should be very sparse, i.e., mostly zeroes. For instance, for docid 9602 you should print something like this:\n",
        "\n",
        "```\n",
        "Positions of non-zeros in column of docid 9602 of M_ngram_doc\n",
        "\n",
        "Clean message:\n",
        " emergenciescat que puc fer i que no faqs del coronavirus a 14 de mar si us plau demanem difusioNon-zeros in corresponding row:\n",
        " emergenciescat que puc fer i que no faqs del coronavirus a 14 de mar si us plau demanem difusio\n",
        " \n",
        "Non-zeros in corresponding row:\n",
        " ['911 (si us plau)', '1222 (emergenciescat que puc)', '1223 (que puc fer)', '1224 (puc fer que)', '1225 (fer que no)', '2575 (14 de mar)', '39134 (que no faqs)', '39135 (no faqs del)', '39136 (faqs del coronavirus)', '39137 (del coronavirus 14)', '39138 (coronavirus 14 de)', '39139 (de mar si)', '39140 (mar si us)', '39141 (us plau demanem)', '39142 (plau demanem difusio)']\n",
        " ```\n",
        "\n",
        "Note that the specific ngram ids you will get depend on your cleanup process, and that the output is in ascending order of ngram number, not in the same ordering in which the ngrams appear in the message.\n",
        "\n",
        "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuxkjfHZHnnc"
      },
      "source": [
        "<font size=\"+1\" color=\"red\">Replace this cell with your code for printing rows 9602 and 941 of the M_ngram_doc matrix.</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docids = [9602, 941]\n",
        "\n",
        "for docid in docids:\n",
        "    print(f'Positions of non-zeros in column of docid {docid} of M_ngram_doc\\n')\n",
        "    print(f'Clean message:\\n  {clean(messages[docid])}\\n')\n",
        "    print('Non-zeros in corresponding row:\\n')\n",
        "    ngr = [f'{i} ({index_to_ngram[i]})' for i in range(num_distinct_ngrams) if M_ngram_doc[i][docid] == True]\n",
        "    print(ngr)\n",
        "    print('\\n-------------------------------------\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0njBvi6Yd7u_",
        "outputId": "0b2e5a01-aeb2-4bf4-cafc-188d3db130c2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positions of non-zeros in column of docid 9602 of M_ngram_doc\n",
            "\n",
            "Clean message:\n",
            "  emergenciescat que puc fer i que no faqs del coronavirus a 14 de marc si us plau demanem difusio\n",
            "\n",
            "Non-zeros in corresponding row:\n",
            "\n",
            "['910 (si us plau)', '1221 (emergenciescat que puc)', '1222 (que puc fer)', '1223 (puc fer que)', '1224 (fer que no)', '2573 (14 de marc)', '39115 (que no faqs)', '39116 (no faqs del)', '39117 (faqs del coronavirus)', '39118 (del coronavirus 14)', '39119 (coronavirus 14 de)', '39120 (de marc si)', '39121 (marc si us)', '39122 (us plau demanem)', '39123 (plau demanem difusio)']\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "Positions of non-zeros in column of docid 941 of M_ngram_doc\n",
            "\n",
            "Clean message:\n",
            "  hospiolot usem de forma responsable els recursos sanitaris061 urgencies per coronavirus i sanitaries012 consultes general\n",
            "\n",
            "Non-zeros in corresponding row:\n",
            "\n",
            "['1474 (usem de forma)', '1475 (de forma responsable)', '1476 (forma responsable els)', '1477 (responsable els recursos)', '1478 (els recursos sanitaris061)', '1479 (recursos sanitaris061 urgencies)', '1480 (sanitaris061 urgencies per)', '1481 (urgencies per coronavirus)', '1482 (per coronavirus sanitaries012)', '1483 (coronavirus sanitaries012 consultes)', '10257 (hospiolot usem de)', '10258 (sanitaries012 consultes general)']\n",
            "\n",
            "-------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP8wgsMYHnnc"
      },
      "source": [
        "# 5. Implement a permutation generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_Qe8g0cHnnc"
      },
      "source": [
        "Implement the function `random_permutation(k)`, which should generate a random permutation of the array `[0, 2, 3, ..., k-1]`. Tip: the function [random.shuffle](https://docs.python.org/3/library/random.html#random.shuffle) might be useful. If you want to use `range(...)`, which returns an iterator, you will need to convert the iterator to a list by using `list(range(...))`.\n",
        "\n",
        "Remember to test your code. For instance, a permutation of 20 elements should look like this:\n",
        "\n",
        "```\n",
        "[14, 10, 0, 8, 4, 12, 5, 19, 6, 9, 15, 13, 16, 2, 17, 11, 7, 3, 18, 1]\n",
        "```\n",
        "\n",
        "Every number appears only once, and all numbers from 0 to 19 appear in the permutation.\n",
        "\n",
        "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsN0nLU7Hnnd"
      },
      "source": [
        "<font size=\"+1\" color=\"red\">Replace this cell with your code for \"random_permutation\"</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_permutation(k):\n",
        "  return list(np.random.permutation(k))\n"
      ],
      "metadata": {
        "id": "B8Ap-HmwamE8"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzBHIoXGHnnd"
      },
      "source": [
        "Further test this by applying the same permutation on two lists. The code below, which you must leave as-is,  should print both lists in the same ordering, so that *alpha* is in the same position of *a*, *beta* in the same position as *b*, and so on.\n",
        "\n",
        "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-t9cHVy-Hnnd",
        "outputId": "adef811e-ba02-4ba6-a2c2-472faf1fba78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test one permutation:\n",
            "['3 (tƒ´n)', '2 (do)', '4 (chƒÅr)', '5 (pƒÅ·πÖc)', '1 (ek)']\n",
            "['3 (tri)', '2 (dva)', '4 (ƒçetiri)', '5 (pet)', '1 (jedan)']\n",
            "\n",
            "Test another permutation\n",
            "['1 (ek)', '3 (tƒ´n)', '5 (pƒÅ·πÖc)', '4 (chƒÅr)', '2 (do)']\n",
            "['1 (jedan)', '3 (tri)', '5 (pet)', '4 (ƒçetiri)', '2 (dva)']\n"
          ]
        }
      ],
      "source": [
        "# LEAVE AS-IS\n",
        "\n",
        "# Permute a list according to a permutation\n",
        "def permuter(original_list, permutation):\n",
        "    permuted_list = []\n",
        "    for index in permutation:\n",
        "        permuted_list.append(original_list[index])\n",
        "    return permuted_list\n",
        "\n",
        "# Code for testing permutations\n",
        "original_list_1 = [\"1 (ek)\", \"2 (do)\", \"3 (tƒ´n)\", \"4 (chƒÅr)\", \"5 (pƒÅ·πÖc)\"]\n",
        "original_list_2 = [\"1 (jedan)\", \"2 (dva)\", \"3 (tri)\", \"4 (ƒçetiri)\", \"5 (pet)\"]\n",
        "\n",
        "print(\"Test one permutation:\")\n",
        "permutation_1 = random_permutation(5)\n",
        "print(permuter(original_list_1, permutation_1))\n",
        "print(permuter(original_list_2, permutation_1))\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Test another permutation\")\n",
        "permutation_2 = random_permutation(5)\n",
        "print(permuter(original_list_1, permutation_2))\n",
        "print(permuter(original_list_2, permutation_2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ntQ5T_0Hnne"
      },
      "source": [
        "# 6. Compute the signature of each document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V49hGtOeHnne"
      },
      "source": [
        "Now comes the core of the algorithm. We will create a new matrix `M_signature_doc` having a small number of rows (the *signature size*), which will be equivalent to the number of permutations we use. The number of columns will continue being the number of documents.\n",
        "\n",
        "First, we create the permutations and store them in an array of arrays named `permutations`, with the following code, which you should leave as-is.\n",
        "\n",
        "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSdW4qxuHnne",
        "outputId": "68eb5db5-30b5-4e3d-f306-568681e88cb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Permutation 0: 5882, 22945, 62979, ...\n",
            "Permutation 1: 14253, 33072, 46841, ...\n",
            "Permutation 2: 31711, 60954, 38201, ...\n",
            "Permutation 3: 66748, 64715, 15408, ...\n",
            "Permutation 4: 18976, 37172, 29839, ...\n"
          ]
        }
      ],
      "source": [
        "# Leave this code as-is\n",
        "\n",
        "NUM_PERMUTATIONS = 5\n",
        "\n",
        "permutations = []\n",
        "\n",
        "# Create the permutations\n",
        "for i in range(NUM_PERMUTATIONS):\n",
        "    permutation = random_permutation(num_distinct_ngrams)\n",
        "    permutations.append(random_permutation(num_distinct_ngrams))\n",
        "    \n",
        "# Visualize the permutations by printing their first 3 elements\n",
        "for i in range(len(permutations)):\n",
        "    permutation = permutations[i]\n",
        "    print(\"Permutation %d: %d, %d, %d, ...\" % (i, permutation[0], permutation[1], permutation[2] ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbtYFLksHnnf"
      },
      "source": [
        "Now, you implement the signature construction. The matrix `M_signature_doc` should contain in row *i*, column *j*, the first ngram (the \"minimum\" one) that is present in a column (document), according to the order given by a permutation.\n",
        "\n",
        "This process may take a few minutes to be completed. You can use the following template:\n",
        "\n",
        "```python\n",
        "M_signature_doc = np.full((NUM_PERMUTATIONS, len(messages)), np.nan)\n",
        "\n",
        "# Find the first ngram in a document, according to a permutation\n",
        "def find_first_one(docid, permutation):\n",
        "    for shingle_id in permutation:\n",
        "        if M_ngram_doc[shingle_id, docid] == True:\n",
        "            return shingle_id\n",
        "    return -1\n",
        "\n",
        "# Create permutations\n",
        "for permutation_num in range(NUM_PERMUTATIONS):\n",
        "    print(\"Creating signatures for permutation %d/%d\" % (permutation_num+1, NUM_PERMUTATIONS))\n",
        "    permutation = permutations[permutation_num]\n",
        "    for docid in range(len(messages)):\n",
        "        if docid % 1000 == 0:\n",
        "            print(\"- Scanning document %d of %d\" % (docid, len(messages)))\n",
        "        # replace this comment with your code\n",
        "```\n",
        "\n",
        "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2z4uOj4LHnnf"
      },
      "source": [
        "<font size=\"+1\" color=\"red\">Replace this cell with your code for creating M_signature_doc</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "M_signature_doc = np.full((NUM_PERMUTATIONS, len(messages)), np.nan)\n",
        "\n",
        "# Find the first ngram in a document, according to a permutation\n",
        "def find_first_one(docid, permutation):\n",
        "    for shingle_id in permutation:\n",
        "        if M_ngram_doc[shingle_id, docid] == True:\n",
        "            return shingle_id\n",
        "    return -1\n",
        "\n",
        "# Create permutations\n",
        "for permutation_num in range(NUM_PERMUTATIONS):\n",
        "    print(\"Creating signatures for permutation %d/%d\" % (permutation_num+1, NUM_PERMUTATIONS))\n",
        "    permutation = permutations[permutation_num]\n",
        "    for docid in range(len(messages)):\n",
        "        if docid % 1000 == 0:\n",
        "            print(\"- Scanning document %d of %d\" % (docid, len(messages)))\n",
        "        # replace this comment with your code\n",
        "        M_signature_doc[permutation_num][docid] = find_first_one(docid, permutation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqkMtV8Mz3-S",
        "outputId": "22ba9efa-64d6-42a1-f687-172850fa30e3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating signatures for permutation 1/5\n",
            "- Scanning document 0 of 10000\n",
            "- Scanning document 1000 of 10000\n",
            "- Scanning document 2000 of 10000\n",
            "- Scanning document 3000 of 10000\n",
            "- Scanning document 4000 of 10000\n",
            "- Scanning document 5000 of 10000\n",
            "- Scanning document 6000 of 10000\n",
            "- Scanning document 7000 of 10000\n",
            "- Scanning document 8000 of 10000\n",
            "- Scanning document 9000 of 10000\n",
            "Creating signatures for permutation 2/5\n",
            "- Scanning document 0 of 10000\n",
            "- Scanning document 1000 of 10000\n",
            "- Scanning document 2000 of 10000\n",
            "- Scanning document 3000 of 10000\n",
            "- Scanning document 4000 of 10000\n",
            "- Scanning document 5000 of 10000\n",
            "- Scanning document 6000 of 10000\n",
            "- Scanning document 7000 of 10000\n",
            "- Scanning document 8000 of 10000\n",
            "- Scanning document 9000 of 10000\n",
            "Creating signatures for permutation 3/5\n",
            "- Scanning document 0 of 10000\n",
            "- Scanning document 1000 of 10000\n",
            "- Scanning document 2000 of 10000\n",
            "- Scanning document 3000 of 10000\n",
            "- Scanning document 4000 of 10000\n",
            "- Scanning document 5000 of 10000\n",
            "- Scanning document 6000 of 10000\n",
            "- Scanning document 7000 of 10000\n",
            "- Scanning document 8000 of 10000\n",
            "- Scanning document 9000 of 10000\n",
            "Creating signatures for permutation 4/5\n",
            "- Scanning document 0 of 10000\n",
            "- Scanning document 1000 of 10000\n",
            "- Scanning document 2000 of 10000\n",
            "- Scanning document 3000 of 10000\n",
            "- Scanning document 4000 of 10000\n",
            "- Scanning document 5000 of 10000\n",
            "- Scanning document 6000 of 10000\n",
            "- Scanning document 7000 of 10000\n",
            "- Scanning document 8000 of 10000\n",
            "- Scanning document 9000 of 10000\n",
            "Creating signatures for permutation 5/5\n",
            "- Scanning document 0 of 10000\n",
            "- Scanning document 1000 of 10000\n",
            "- Scanning document 2000 of 10000\n",
            "- Scanning document 3000 of 10000\n",
            "- Scanning document 4000 of 10000\n",
            "- Scanning document 5000 of 10000\n",
            "- Scanning document 6000 of 10000\n",
            "- Scanning document 7000 of 10000\n",
            "- Scanning document 8000 of 10000\n",
            "- Scanning document 9000 of 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvkI054_Hnnf"
      },
      "source": [
        "Test your code by checking the signatures of two documents that are near-duplicates,using the next code, which you should leave as-is. Being near-duplicates, we expect these should have many ngrams in common, and hence, with high probability they will have many elements in common in their signatures.\n",
        "\n",
        "Note that your ngrams and signatures vectors might be different than what we show here, given the differences in cleaning procedures and the randomness of the permutations.\n",
        "\n",
        "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgsWYZLgHnng",
        "outputId": "f130c0b4-bc03-4525-a565-f9be73ddbd69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document #385\n",
            "Message       : RT @gencat: üî¥ El @govern de la @gencat anuncia el #confinament de tot Catalunya.\n",
            "\n",
            "Davant l‚Äôemerg√®ncia de la #COVID19, el missatge √©s clau:‚Ä¶\n",
            "Clean message : gencat el govern de la gencat anuncia el confinament de tot catalunyadavant lemergencia de la covid19 el missatge es clau\n",
            "Ngrams        : [61, 3332, 3458, 4102, 4908, 4909, 4910, 4911, 4912, 4913, 4914, 4915, 4916, 4917, 4918, 4919, 4920, 4921]\n",
            "Signature     : [4918.0, 61.0, 4917.0, 4915.0, 3332.0]\n",
            "\n",
            "Document #627\n",
            "Message       : PROCICAT_CORONAVIRUS. El @govern de la @gencat anuncia el #confinament de tot Catalunya. Davant l‚Äôemerg√®ncia de la #COVID19, el missatge √©s clau: limitar la mobilitat ajudar√† a evitar la propagaci√≥ del #coronavirus. Evitem despla√ßaments i redu√Øm la vida social #JoEmQuedoACasa\n",
            "Clean message : procicatcoronavirus el govern de la gencat anuncia el confinament de tot catalunya davant lemergencia de la covid19 el missatge es clau limitar la mobilitat ajudara a evitar la propagacio del coronavirus evitem desplacaments i reduim la vida social joemquedoacasa\n",
            "Ngrams        : [61, 3332, 3458, 4102, 4908, 4909, 4910, 4911, 4912, 4913, 4914, 4915, 4916, 4917, 4918, 4919, 4920, 4921]\n",
            "Signature     : [4918.0, 61.0, 4917.0, 7242.0, 3332.0]\n"
          ]
        }
      ],
      "source": [
        "# Leave this code as-is\n",
        "\n",
        "def extract_ngrams(docid):\n",
        "    return [x for x in range(num_distinct_ngrams) if M_ngram_doc[x, i] == True]\n",
        "\n",
        "def extract_signature(docid):\n",
        "    return [M_signature_doc[x, docid] for x in range(NUM_PERMUTATIONS)]\n",
        "\n",
        "def print_sig(messages, M_ngram_doc, M_signature_doc, i):\n",
        "    print(\"Document #%d\" % i)\n",
        "    print(\"Message       : %s\" % messages[i])\n",
        "    print(\"Clean message : %s\" % clean(messages[i]))\n",
        "    print(\"Ngrams        : %s\" % extract_ngrams(i))\n",
        "    print(\"Signature     : %s\" % extract_signature(i))\n",
        "\n",
        "        \n",
        "i = 385\n",
        "j = 627\n",
        "\n",
        "print_sig(messages, M_ngram_doc, M_signature_doc, i )\n",
        "\n",
        "print()\n",
        "\n",
        "print_sig(messages, M_ngram_doc, M_signature_doc, j )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbOtS3IuHnnh"
      },
      "source": [
        "# 7. Compare all pairs of signatures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPBH_YDiHnnh"
      },
      "source": [
        "Now we are ready to compare all documents by their signatures, instead of by their content.\n",
        "\n",
        "We will consider that if two documents have *similarity == 1.0* they are a *full signature match*, and if two documents have *0.2 < similarity < 1.0* they are a *partial signature match*. In both cases, this may mean the documents are duplicates or near duplicates.\n",
        "\n",
        "Write code to compare all pairs of documents. Use the following template:\n",
        "\n",
        "```python\n",
        "is_possible_duplicate = {}\n",
        "\n",
        "# Iterate through all documents\n",
        "for docid1 in range(len(messages)):\n",
        "\n",
        "     # Do not examine again a document that is a possible duplicate\n",
        "    if docid not in is_possible_duplicate:\n",
        "\n",
        "        # Counters for full and partial signature matches\n",
        "        count_sig_full_matches = 0\n",
        "        count_sig_partial_matches = 0\n",
        "\n",
        "        # Extract the signature of the doc1\n",
        "        signature1 = extract_signature(docid1)\n",
        "        if docid1 % 500 == 0:\n",
        "            print(\"%d/%d documents scanned\" % (docid1, len(messages)))\n",
        "\n",
        "        # Iterate through documents with docid larger than doc1\n",
        "        for docid2 in range(docid1+1, len(messages)):\n",
        "\n",
        "            # If this has not already been marked as duplicate of another document\n",
        "            if docid2 not in is_possible_duplicate:\n",
        "\n",
        "                # Extract signature of doc2\n",
        "                signature2 = extract_signature(docid2)\n",
        "\n",
        "                # REPLACE THIS COMMENT WITH YOUR CODE:\n",
        "                # - Increase count_sig_full_matches and count_sig_partial_matches as needed\n",
        "                # - Include docid2 in is_possible_duplicate if needed\n",
        "\n",
        "        # REPLACE THIS COMMENT WITH YOUR CODE\n",
        "        # - If the number of partial matches plus full matches exceeds a threshold\n",
        "        #   print the document doc1 and indicate how many matches of each type it has\n",
        "```\n",
        "\n",
        "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5eU91bbHnnh"
      },
      "source": [
        "<font size=\"+1\" color=\"red\">Replace this cell with your code for comparing all signatures; print all documents that have at least 50 signature matches, considering both full matches and partial matches.</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "is_possible_duplicate = {}\n",
        "\n",
        "thereshold = 50\n",
        "documents_thereshold = 0\n",
        "\n",
        "selected = {'difference': -500, 'docid': 0, 'full_matches': 0, 'partial_matches': 0}\n",
        "\n",
        "# Iterate through all documents\n",
        "for docid1 in range(len(messages)):\n",
        "\n",
        "     # Do not examine again a document that is a possible duplicate\n",
        "    if docid not in is_possible_duplicate:\n",
        "\n",
        "        # Counters for full and partial signature matches\n",
        "        count_sig_full_matches = 0\n",
        "        count_sig_partial_matches = 0\n",
        "\n",
        "        # Extract the signature of the doc1\n",
        "        signature1 = extract_signature(docid1)\n",
        "        if docid1 % 500 == 0:\n",
        "            print(\"%d/%d documents scanned\" % (docid1, len(messages)))\n",
        "\n",
        "        # Iterate through documents with docid larger than doc1\n",
        "        for docid2 in range(docid1+1, len(messages)):\n",
        "\n",
        "            # If this has not already been marked as duplicate of another document\n",
        "            if docid2 not in is_possible_duplicate:\n",
        "\n",
        "                # Extract signature of doc2\n",
        "                signature2 = extract_signature(docid2)\n",
        "\n",
        "                # REPLACE THIS COMMENT WITH YOUR CODE:\n",
        "                # - Increase count_sig_full_matches and count_sig_partial_matches as needed\n",
        "                # - Include docid2 in is_possible_duplicate if needed\n",
        "                jaccard_sim = jaccard_similarity(signature1, signature2)\n",
        "\n",
        "                if jaccard_sim > 0.2  and  jaccard_sim <= 1:\n",
        "\n",
        "                  if jaccard_sim == 1: count_sig_full_matches += 1\n",
        "                  else: count_sig_partial_matches += 1\n",
        "\n",
        "                  is_possible_duplicate[docid1]= docid2\n",
        "\n",
        "\n",
        "        # REPLACE THIS COMMENT WITH YOUR CODE\n",
        "        # - If the number of partial matches plus full matches exceeds a threshold\n",
        "        #   print the document doc1 and indicate how many matches of each type it has\n",
        "        \n",
        "        if count_sig_full_matches + count_sig_partial_matches > thereshold:\n",
        "          print(f'Document with id {docid1} has {count_sig_full_matches} full and {count_sig_partial_matches} partial matches')\n",
        "          documents_thereshold += 1\n",
        "          m = count_sig_full_matches - count_sig_partial_matches\n",
        "          if m > selected['difference']:\n",
        "            selected['difference'] = m\n",
        "            selected['docid'] = docid1\n",
        "            selected['full_matches'] = count_sig_full_matches\n",
        "            selected['partial_matches'] = count_sig_partial_matches\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "benlVcM_2lgm",
        "outputId": "45c2fa1f-2334-48ce-9c3a-71bb9bdaaffd"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0/10000 documents scanned\n",
            "Document with id 16 has 71 full and 19 partial matches\n",
            "Document with id 42 has 46 full and 6 partial matches\n",
            "Document with id 53 has 57 full and 0 partial matches\n",
            "Document with id 73 has 16 full and 35 partial matches\n",
            "Document with id 83 has 63 full and 0 partial matches\n",
            "Document with id 84 has 70 full and 19 partial matches\n",
            "Document with id 85 has 45 full and 6 partial matches\n",
            "Document with id 166 has 56 full and 0 partial matches\n",
            "Document with id 167 has 55 full and 0 partial matches\n",
            "Document with id 168 has 54 full and 0 partial matches\n",
            "Document with id 172 has 53 full and 0 partial matches\n",
            "Document with id 174 has 52 full and 0 partial matches\n",
            "Document with id 176 has 51 full and 0 partial matches\n",
            "Document with id 192 has 62 full and 0 partial matches\n",
            "Document with id 221 has 61 full and 0 partial matches\n",
            "Document with id 280 has 60 full and 0 partial matches\n",
            "Document with id 307 has 17 full and 71 partial matches\n",
            "Document with id 328 has 65 full and 0 partial matches\n",
            "Document with id 331 has 64 full and 0 partial matches\n",
            "Document with id 412 has 63 full and 0 partial matches\n",
            "Document with id 425 has 69 full and 18 partial matches\n",
            "Document with id 438 has 59 full and 0 partial matches\n",
            "Document with id 448 has 62 full and 0 partial matches\n",
            "Document with id 470 has 58 full and 0 partial matches\n",
            "Document with id 484 has 57 full and 0 partial matches\n",
            "500/10000 documents scanned\n",
            "Document with id 557 has 56 full and 0 partial matches\n",
            "Document with id 578 has 56 full and 0 partial matches\n",
            "Document with id 587 has 55 full and 0 partial matches\n",
            "Document with id 620 has 68 full and 18 partial matches\n",
            "Document with id 688 has 67 full and 18 partial matches\n",
            "Document with id 730 has 55 full and 0 partial matches\n",
            "Document with id 743 has 54 full and 0 partial matches\n",
            "Document with id 793 has 61 full and 0 partial matches\n",
            "Document with id 851 has 66 full and 18 partial matches\n",
            "Document with id 881 has 54 full and 0 partial matches\n",
            "Document with id 939 has 65 full and 18 partial matches\n",
            "Document with id 964 has 53 full and 0 partial matches\n",
            "Document with id 982 has 60 full and 0 partial matches\n",
            "Document with id 991 has 59 full and 0 partial matches\n",
            "Document with id 992 has 58 full and 0 partial matches\n",
            "Document with id 998 has 52 full and 0 partial matches\n",
            "1000/10000 documents scanned\n",
            "Document with id 1009 has 57 full and 0 partial matches\n",
            "Document with id 1030 has 64 full and 18 partial matches\n",
            "Document with id 1035 has 16 full and 65 partial matches\n",
            "Document with id 1069 has 63 full and 17 partial matches\n",
            "Document with id 1075 has 2 full and 68 partial matches\n",
            "Document with id 1109 has 53 full and 0 partial matches\n",
            "Document with id 1119 has 62 full and 17 partial matches\n",
            "Document with id 1174 has 61 full and 17 partial matches\n",
            "Document with id 1213 has 60 full and 17 partial matches\n",
            "Document with id 1221 has 59 full and 17 partial matches\n",
            "Document with id 1231 has 51 full and 0 partial matches\n",
            "Document with id 1401 has 58 full and 17 partial matches\n",
            "Document with id 1432 has 57 full and 17 partial matches\n",
            "Document with id 1474 has 56 full and 0 partial matches\n",
            "Document with id 1491 has 52 full and 0 partial matches\n",
            "1500/10000 documents scanned\n",
            "Document with id 1504 has 55 full and 0 partial matches\n",
            "Document with id 1510 has 15 full and 58 partial matches\n",
            "Document with id 1644 has 54 full and 0 partial matches\n",
            "Document with id 1698 has 51 full and 0 partial matches\n",
            "Document with id 1772 has 56 full and 16 partial matches\n",
            "Document with id 1785 has 1 full and 68 partial matches\n",
            "Document with id 1849 has 55 full and 16 partial matches\n",
            "Document with id 1859 has 54 full and 16 partial matches\n",
            "Document with id 1901 has 53 full and 16 partial matches\n",
            "Document with id 1907 has 52 full and 16 partial matches\n",
            "Document with id 1923 has 51 full and 16 partial matches\n",
            "Document with id 1971 has 50 full and 16 partial matches\n",
            "Document with id 1975 has 49 full and 16 partial matches\n",
            "2000/10000 documents scanned\n",
            "Document with id 2051 has 48 full and 16 partial matches\n",
            "Document with id 2059 has 47 full and 16 partial matches\n",
            "Document with id 2062 has 46 full and 16 partial matches\n",
            "Document with id 2103 has 45 full and 16 partial matches\n",
            "Document with id 2148 has 44 full and 16 partial matches\n",
            "Document with id 2180 has 53 full and 0 partial matches\n",
            "Document with id 2181 has 52 full and 0 partial matches\n",
            "Document with id 2183 has 51 full and 0 partial matches\n",
            "Document with id 2199 has 14 full and 45 partial matches\n",
            "Document with id 2205 has 13 full and 45 partial matches\n",
            "Document with id 2206 has 43 full and 14 partial matches\n",
            "Document with id 2209 has 42 full and 14 partial matches\n",
            "Document with id 2359 has 41 full and 14 partial matches\n",
            "Document with id 2427 has 40 full and 14 partial matches\n",
            "2500/10000 documents scanned\n",
            "Document with id 2514 has 39 full and 14 partial matches\n",
            "Document with id 2517 has 38 full and 14 partial matches\n",
            "Document with id 2527 has 37 full and 14 partial matches\n",
            "3000/10000 documents scanned\n",
            "3500/10000 documents scanned\n",
            "Document with id 3752 has 0 full and 68 partial matches\n",
            "4000/10000 documents scanned\n",
            "4500/10000 documents scanned\n",
            "5000/10000 documents scanned\n",
            "Document with id 5040 has 0 full and 67 partial matches\n",
            "Document with id 5077 has 176 full and 0 partial matches\n",
            "Document with id 5080 has 175 full and 0 partial matches\n",
            "Document with id 5081 has 174 full and 0 partial matches\n",
            "Document with id 5083 has 173 full and 0 partial matches\n",
            "Document with id 5109 has 66 full and 0 partial matches\n",
            "Document with id 5117 has 71 full and 0 partial matches\n",
            "Document with id 5129 has 54 full and 0 partial matches\n",
            "Document with id 5146 has 65 full and 0 partial matches\n",
            "Document with id 5155 has 64 full and 0 partial matches\n",
            "Document with id 5200 has 172 full and 0 partial matches\n",
            "Document with id 5211 has 63 full and 0 partial matches\n",
            "Document with id 5225 has 62 full and 0 partial matches\n",
            "Document with id 5248 has 171 full and 0 partial matches\n",
            "Document with id 5250 has 170 full and 0 partial matches\n",
            "Document with id 5252 has 169 full and 0 partial matches\n",
            "Document with id 5257 has 168 full and 0 partial matches\n",
            "Document with id 5262 has 167 full and 0 partial matches\n",
            "Document with id 5267 has 166 full and 0 partial matches\n",
            "Document with id 5271 has 54 full and 0 partial matches\n",
            "Document with id 5273 has 165 full and 0 partial matches\n",
            "Document with id 5282 has 61 full and 0 partial matches\n",
            "Document with id 5316 has 53 full and 0 partial matches\n",
            "Document with id 5319 has 52 full and 0 partial matches\n",
            "Document with id 5334 has 164 full and 0 partial matches\n",
            "Document with id 5339 has 163 full and 0 partial matches\n",
            "Document with id 5343 has 162 full and 0 partial matches\n",
            "Document with id 5349 has 161 full and 0 partial matches\n",
            "Document with id 5372 has 160 full and 0 partial matches\n",
            "Document with id 5393 has 159 full and 0 partial matches\n",
            "Document with id 5394 has 158 full and 0 partial matches\n",
            "Document with id 5400 has 60 full and 0 partial matches\n",
            "Document with id 5403 has 70 full and 0 partial matches\n",
            "Document with id 5404 has 69 full and 0 partial matches\n",
            "Document with id 5426 has 157 full and 0 partial matches\n",
            "Document with id 5428 has 53 full and 0 partial matches\n",
            "Document with id 5429 has 156 full and 0 partial matches\n",
            "Document with id 5430 has 52 full and 0 partial matches\n",
            "Document with id 5437 has 155 full and 0 partial matches\n",
            "Document with id 5440 has 154 full and 0 partial matches\n",
            "Document with id 5445 has 51 full and 0 partial matches\n",
            "Document with id 5459 has 68 full and 0 partial matches\n",
            "Document with id 5475 has 153 full and 0 partial matches\n",
            "Document with id 5484 has 152 full and 0 partial matches\n",
            "5500/10000 documents scanned\n",
            "Document with id 5509 has 151 full and 0 partial matches\n",
            "Document with id 5515 has 150 full and 0 partial matches\n",
            "Document with id 5517 has 149 full and 0 partial matches\n",
            "Document with id 5520 has 148 full and 0 partial matches\n",
            "Document with id 5522 has 59 full and 0 partial matches\n",
            "Document with id 5525 has 58 full and 0 partial matches\n",
            "Document with id 5532 has 57 full and 0 partial matches\n",
            "Document with id 5539 has 56 full and 0 partial matches\n",
            "Document with id 5542 has 67 full and 0 partial matches\n",
            "Document with id 5558 has 55 full and 0 partial matches\n",
            "Document with id 5561 has 147 full and 0 partial matches\n",
            "Document with id 5564 has 54 full and 0 partial matches\n",
            "Document with id 5579 has 53 full and 0 partial matches\n",
            "Document with id 5583 has 51 full and 0 partial matches\n",
            "Document with id 5589 has 52 full and 0 partial matches\n",
            "Document with id 5592 has 66 full and 0 partial matches\n",
            "Document with id 5612 has 51 full and 0 partial matches\n",
            "Document with id 5619 has 65 full and 0 partial matches\n",
            "Document with id 5636 has 80 full and 0 partial matches\n",
            "Document with id 5642 has 64 full and 0 partial matches\n",
            "Document with id 5646 has 63 full and 0 partial matches\n",
            "Document with id 5648 has 62 full and 0 partial matches\n",
            "Document with id 5662 has 61 full and 0 partial matches\n",
            "Document with id 5664 has 60 full and 0 partial matches\n",
            "Document with id 5698 has 79 full and 0 partial matches\n",
            "Document with id 5700 has 78 full and 0 partial matches\n",
            "Document with id 5725 has 77 full and 0 partial matches\n",
            "Document with id 5733 has 76 full and 0 partial matches\n",
            "Document with id 5740 has 75 full and 0 partial matches\n",
            "Document with id 5751 has 146 full and 0 partial matches\n",
            "Document with id 5762 has 74 full and 0 partial matches\n",
            "Document with id 5784 has 145 full and 0 partial matches\n",
            "Document with id 5787 has 144 full and 0 partial matches\n",
            "Document with id 5818 has 59 full and 0 partial matches\n",
            "Document with id 5822 has 143 full and 0 partial matches\n",
            "Document with id 5858 has 142 full and 0 partial matches\n",
            "Document with id 5885 has 141 full and 0 partial matches\n",
            "Document with id 5891 has 140 full and 0 partial matches\n",
            "Document with id 5892 has 139 full and 0 partial matches\n",
            "Document with id 5901 has 138 full and 0 partial matches\n",
            "Document with id 5902 has 137 full and 0 partial matches\n",
            "Document with id 5917 has 136 full and 0 partial matches\n",
            "Document with id 5918 has 58 full and 0 partial matches\n",
            "Document with id 5957 has 57 full and 0 partial matches\n",
            "Document with id 5960 has 56 full and 0 partial matches\n",
            "Document with id 5968 has 73 full and 0 partial matches\n",
            "Document with id 5998 has 55 full and 0 partial matches\n",
            "6000/10000 documents scanned\n",
            "Document with id 6005 has 72 full and 0 partial matches\n",
            "Document with id 6010 has 71 full and 0 partial matches\n",
            "Document with id 6024 has 135 full and 0 partial matches\n",
            "Document with id 6026 has 134 full and 0 partial matches\n",
            "Document with id 6055 has 133 full and 0 partial matches\n",
            "Document with id 6063 has 132 full and 0 partial matches\n",
            "Document with id 6069 has 131 full and 0 partial matches\n",
            "Document with id 6118 has 54 full and 0 partial matches\n",
            "Document with id 6130 has 70 full and 0 partial matches\n",
            "Document with id 6157 has 130 full and 0 partial matches\n",
            "Document with id 6160 has 129 full and 0 partial matches\n",
            "Document with id 6164 has 128 full and 0 partial matches\n",
            "Document with id 6165 has 127 full and 0 partial matches\n",
            "Document with id 6169 has 126 full and 0 partial matches\n",
            "Document with id 6171 has 125 full and 0 partial matches\n",
            "Document with id 6189 has 124 full and 0 partial matches\n",
            "Document with id 6212 has 123 full and 0 partial matches\n",
            "Document with id 6213 has 122 full and 0 partial matches\n",
            "Document with id 6215 has 121 full and 0 partial matches\n",
            "Document with id 6219 has 120 full and 0 partial matches\n",
            "Document with id 6237 has 119 full and 0 partial matches\n",
            "Document with id 6268 has 118 full and 0 partial matches\n",
            "Document with id 6312 has 53 full and 0 partial matches\n",
            "Document with id 6315 has 52 full and 0 partial matches\n",
            "Document with id 6324 has 51 full and 0 partial matches\n",
            "Document with id 6369 has 69 full and 0 partial matches\n",
            "Document with id 6374 has 68 full and 0 partial matches\n",
            "Document with id 6391 has 67 full and 0 partial matches\n",
            "Document with id 6393 has 66 full and 0 partial matches\n",
            "Document with id 6405 has 65 full and 0 partial matches\n",
            "Document with id 6408 has 64 full and 0 partial matches\n",
            "Document with id 6452 has 117 full and 0 partial matches\n",
            "Document with id 6466 has 63 full and 0 partial matches\n",
            "Document with id 6496 has 62 full and 0 partial matches\n",
            "6500/10000 documents scanned\n",
            "Document with id 6510 has 61 full and 0 partial matches\n",
            "Document with id 6511 has 60 full and 0 partial matches\n",
            "Document with id 6517 has 59 full and 0 partial matches\n",
            "Document with id 6636 has 116 full and 0 partial matches\n",
            "Document with id 6698 has 115 full and 0 partial matches\n",
            "Document with id 6734 has 114 full and 0 partial matches\n",
            "Document with id 6738 has 113 full and 0 partial matches\n",
            "Document with id 6739 has 112 full and 0 partial matches\n",
            "Document with id 6760 has 111 full and 0 partial matches\n",
            "Document with id 6761 has 110 full and 0 partial matches\n",
            "Document with id 6770 has 109 full and 0 partial matches\n",
            "Document with id 6774 has 108 full and 0 partial matches\n",
            "Document with id 6780 has 107 full and 0 partial matches\n",
            "Document with id 6786 has 106 full and 0 partial matches\n",
            "Document with id 6787 has 105 full and 0 partial matches\n",
            "Document with id 6824 has 104 full and 0 partial matches\n",
            "Document with id 6854 has 103 full and 0 partial matches\n",
            "Document with id 6909 has 102 full and 0 partial matches\n",
            "Document with id 6943 has 101 full and 0 partial matches\n",
            "Document with id 6996 has 58 full and 0 partial matches\n",
            "Document with id 6997 has 57 full and 0 partial matches\n",
            "7000/10000 documents scanned\n",
            "Document with id 7012 has 56 full and 0 partial matches\n",
            "Document with id 7027 has 55 full and 0 partial matches\n",
            "Document with id 7045 has 100 full and 0 partial matches\n",
            "Document with id 7046 has 54 full and 0 partial matches\n",
            "Document with id 7048 has 53 full and 0 partial matches\n",
            "Document with id 7066 has 52 full and 0 partial matches\n",
            "Document with id 7067 has 51 full and 0 partial matches\n",
            "Document with id 7189 has 99 full and 0 partial matches\n",
            "Document with id 7242 has 98 full and 0 partial matches\n",
            "Document with id 7249 has 97 full and 0 partial matches\n",
            "Document with id 7254 has 96 full and 0 partial matches\n",
            "Document with id 7258 has 95 full and 0 partial matches\n",
            "Document with id 7316 has 94 full and 0 partial matches\n",
            "Document with id 7320 has 93 full and 0 partial matches\n",
            "Document with id 7328 has 92 full and 0 partial matches\n",
            "Document with id 7376 has 91 full and 0 partial matches\n",
            "Document with id 7390 has 90 full and 0 partial matches\n",
            "7500/10000 documents scanned\n",
            "Document with id 7511 has 89 full and 0 partial matches\n",
            "Document with id 7530 has 88 full and 0 partial matches\n",
            "Document with id 7531 has 87 full and 0 partial matches\n",
            "Document with id 7532 has 86 full and 0 partial matches\n",
            "Document with id 7533 has 85 full and 0 partial matches\n",
            "Document with id 7539 has 84 full and 0 partial matches\n",
            "Document with id 7554 has 83 full and 0 partial matches\n",
            "Document with id 7600 has 82 full and 0 partial matches\n",
            "Document with id 7672 has 81 full and 0 partial matches\n",
            "Document with id 7702 has 80 full and 0 partial matches\n",
            "Document with id 7711 has 79 full and 0 partial matches\n",
            "Document with id 7838 has 78 full and 0 partial matches\n",
            "Document with id 7884 has 77 full and 0 partial matches\n",
            "Document with id 7929 has 76 full and 0 partial matches\n",
            "Document with id 7931 has 75 full and 0 partial matches\n",
            "Document with id 7958 has 74 full and 0 partial matches\n",
            "8000/10000 documents scanned\n",
            "Document with id 8000 has 73 full and 0 partial matches\n",
            "Document with id 8013 has 72 full and 0 partial matches\n",
            "Document with id 8016 has 71 full and 0 partial matches\n",
            "Document with id 8025 has 70 full and 0 partial matches\n",
            "Document with id 8050 has 69 full and 0 partial matches\n",
            "Document with id 8160 has 68 full and 0 partial matches\n",
            "Document with id 8165 has 67 full and 0 partial matches\n",
            "Document with id 8174 has 66 full and 0 partial matches\n",
            "Document with id 8176 has 65 full and 0 partial matches\n",
            "Document with id 8179 has 64 full and 0 partial matches\n",
            "Document with id 8184 has 63 full and 0 partial matches\n",
            "Document with id 8186 has 62 full and 0 partial matches\n",
            "Document with id 8189 has 61 full and 0 partial matches\n",
            "Document with id 8268 has 60 full and 0 partial matches\n",
            "Document with id 8276 has 59 full and 0 partial matches\n",
            "Document with id 8297 has 58 full and 0 partial matches\n",
            "Document with id 8308 has 57 full and 0 partial matches\n",
            "Document with id 8383 has 56 full and 0 partial matches\n",
            "8500/10000 documents scanned\n",
            "Document with id 8513 has 55 full and 0 partial matches\n",
            "Document with id 8560 has 54 full and 0 partial matches\n",
            "Document with id 8585 has 53 full and 0 partial matches\n",
            "Document with id 8662 has 52 full and 0 partial matches\n",
            "Document with id 8664 has 51 full and 0 partial matches\n",
            "9000/10000 documents scanned\n",
            "9500/10000 documents scanned\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'In total {documents_thereshold} documents have at least {thereshold} signature matches, considering both full matches and partial matches.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3TZEGY37Tjq",
        "outputId": "7f24a71e-2bb8-4a6f-e558-c03372d4343f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In total 289 documents have at least 50 signature matches, considering both full matches and partial matches.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GxXPw7EHnnh"
      },
      "source": [
        "<font size=\"+1\" color=\"red\">Replace this cell with a brief commentary, based on the results above, about one tweet that has a substantial number of complete matches, but few partial matches. Include the full text of the original tweet. Comment on why you believe this tweet is not being changed much when copied or re-tweeted.</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'The tweet with largest difference between full matches and partial matches is:\\n{messages[selected[\"docid\"]]}\\n\\n With:\\n\\t- {selected[\"full_matches\"]} full matches\\n\\t- {selected[\"partial_matches\"]} partial matches')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pU3TkeKMVxX",
        "outputId": "f478948b-bb35-41c9-f366-ce18d7c1ba19"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tweet with largest difference between full matches and partial matches is:\n",
            "RT @emergenciescat: Qu√® puc fer i que no? FAQs del #coronavirus a 14 de mar√ß. si us plau, demanem difusi√≥. https://t.co/D5HNxwYjwK\n",
            "\n",
            " With:\n",
            "\t- 176 full matches\n",
            "\t- 0 partial matches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf-wxRbIHnni"
      },
      "source": [
        "<font size=\"+1\" color=\"red\">Replace this cell with a brief commentary, based on the results above, about one tweet that has a substantial number of partial matches, but fewer complete matches. Include the full text of the original tweet and one near duplicate (that cannot be identical to the original tweet).</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyh9XqDKHnni"
      },
      "source": [
        "# DELIVER (individually)\n",
        "\n",
        "Remember to read the section on \"delivering your code\" in the [course evaluation guidelines](https://github.com/chatox/data-mining-course/blob/master/upf/upf-evaluation.md).\n",
        "\n",
        "Deliver a zip file containing:\n",
        "\n",
        "* This notebook\n",
        "\n",
        "## Extra points available\n",
        "\n",
        "For more learning and extra points, compare what happens with 3 different ngram sizes (2-grams, 3-grams, 4-grams) in terms of the efficiency (speed) and effectiveness (accuracy). You can include plots for efficiency, and examples for effectiveness.\n",
        "\n",
        "**Note:** if you go for the extra points, add ``<font size=\"+2\" color=\"blue\">Additional results: various ngram sizes</font>`` at the top of your notebook.\n",
        "\n",
        "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_vB3QSvHnni"
      },
      "source": [
        "<font size=\"+2\" color=\"#003300\">I hereby declare that, except for the code provided by the course instructors, all of my code, report, and figures were produced by myself.</font>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}